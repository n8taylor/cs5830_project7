{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a4397f8b382ebb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project 5 Naive Bayes Classifier\n",
    "\n",
    "- [Report](https://docs.google.com/document/d/1U_K9n-OSwi6Ld92fMkoIm5cEyvnQTJYjKHeozIQIst8/edit?usp=sharing)\n",
    "- [Slides](https://docs.google.com/presentation/d/11TlmsBK_qryIzCE8YAoY3G1Eu9zstGp0IyQpT3e0LdY/edit?usp=sharing)\n",
    "- [Dataset](https://archive.ics.uci.edu/dataset/73/mushroom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664f7a90ad922e6a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bffa7796be8306a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'class', \n",
    "    'cap_shape', \n",
    "    'cap_surface',\n",
    "    'cap_color',\n",
    "    'bruises',\n",
    "    'odor',\n",
    "    'gill_attachment',\n",
    "    'gill_spacing',\n",
    "    'gill_size',\n",
    "    'gill_color',\n",
    "    'stalk_shape',\n",
    "    'stalk_root',\n",
    "    'stalk_surface_ar',\n",
    "    'stalk_surface_br',\n",
    "    'stalk_color_ar',\n",
    "    'stalk_color_br',\n",
    "    'veil_type',\n",
    "    'veil_color',\n",
    "    'ring_number',\n",
    "    'ring_type',\n",
    "    'spore_print_color',\n",
    "    'population',\n",
    "    'habitat'\n",
    "]\n",
    "df = pd.read_csv('data/agaricus-lepiota.data', names=features)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c0ced",
   "metadata": {},
   "source": [
    "### Encoding the data for use in Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37425a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values into numerical values\n",
    "labelEncoders = {}\n",
    "for col in df.columns:\n",
    "    labelEncoders[col] = LabelEncoder()\n",
    "    df[col] = labelEncoders[col].fit_transform(df[col])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647abe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = {}  # encoding pairs for reference\n",
    "for col, encoder in labelEncoders.items():\n",
    "    encodings[col] = {encoded: original for encoded, original in enumerate(encoder.classes_)}\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4324f25",
   "metadata": {},
   "source": [
    "### Practicing Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)#, random_state=42)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_pred, labels=[0, 1])\n",
    "print(p, r, f, s)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ed0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f939f1",
   "metadata": {},
   "source": [
    "### A Methodical Approach to Finding the Best Attributes for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ad097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testDataset(dataframe, testCol, attributes=1, verbose=True):\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    # Test a random set of attributes\n",
    "    if type(attributes) == int:\n",
    "        # If more attributes are specified than there are, just use all of them\n",
    "        if attributes > len(df.columns)-1:\n",
    "            attributes = len(df.columns)-1\n",
    "        attributes = df[df.columns[df.columns != testCol]].sample(axis=1, n=attributes).columns\n",
    "        attributes = [attribute for attribute in attributes]\n",
    "        # display([attribute for attribute in attributes])\n",
    "\n",
    "    # Test a specific set of attributes\n",
    "    elif type(attributes) != list:\n",
    "        print('attributes must be an integer or a list of attribute names')\n",
    "        return\n",
    "\n",
    "\n",
    "    # Clear out any records that don't have a valid value for one of the attributes in question\n",
    "    for attribute in attributes:\n",
    "        if attribute == testCol:\n",
    "            print(f'Cannot predict {testCol} using {testCol}')\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            df = df.dropna(subset=attribute)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return\n",
    "    \n",
    "    print(f'Predicting based on Naive Bayes Classifiers using {attributes}:') if verbose else None\n",
    "    # display(df)\n",
    "\n",
    "    f1Scores = []\n",
    "    for j in range(10):\n",
    "        X = df[attributes]\n",
    "        y = df['class']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)#, random_state=42)\n",
    "\n",
    "        classifier = MultinomialNB()\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        p, r, f, s = precision_recall_fscore_support(y_test, y_pred, labels=[0, 1])\n",
    "        f1Scores.append(f)\n",
    "        print(f'Test {j}: precision={p}, recall={r}, f-score={f}, support={s}') if verbose else None\n",
    "        print(classification_report(y_test, y_pred)) if verbose else None\n",
    "        \n",
    "\n",
    "    meanF1s = []\n",
    "    for i in range(len(f1Scores[0])):\n",
    "        f1Total = 0\n",
    "        for score in f1Scores:\n",
    "            f1Total += score[i]\n",
    "        meanF1s.append(f1Total / len(f1Scores))\n",
    "\n",
    "    print(f'Mean F1 scores: f-score={meanF1s}') if verbose else None\n",
    "\n",
    "    f1sTotal = 0\n",
    "    for f1 in meanF1s:\n",
    "        f1sTotal += f1\n",
    "    meanOfF1s = f1sTotal / len(meanF1s)\n",
    "    meanF1s.append(meanOfF1s)\n",
    "\n",
    "    print(f'Mean of mean F1 scores: f-score={meanF1s[-1]}') if verbose else None\n",
    "\n",
    "    return meanF1s, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dbf011",
   "metadata": {},
   "source": [
    "#### Testing Average and Highest F-scores for Each Number of Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fScores = {\n",
    "    'highestFScores': [],\n",
    "    'avgFScores': [],\n",
    "    'winningAttributes': [],\n",
    "    'attributes': []\n",
    "}\n",
    "for i in range(1, len(df.drop('class', axis=1).columns)+1):\n",
    "    fScores['attributes'].append(i)\n",
    "    avgFScore = 0\n",
    "    highestF = 0\n",
    "    bestAttributes = []\n",
    "    for j in range(50):\n",
    "        scores, attributes = testDataset(dataframe=df, testCol='class', attributes=i, verbose=False)\n",
    "        avgFScore += scores[2]\n",
    "        if scores[2] > highestF:\n",
    "            highestF = scores[2]\n",
    "            bestAttributes = attributes\n",
    "    avgFScore /= 50\n",
    "    fScores['avgFScores'].append(avgFScore)\n",
    "    fScores['highestFScores'].append(highestF)\n",
    "    fScores['winningAttributes'].append(bestAttributes)\n",
    "\n",
    "display(fScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e0020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresDF = pd.DataFrame(fScores)\n",
    "scoresDF = scoresDF.sort_values(by='attributes')\n",
    "display(scoresDF)\n",
    "\n",
    "sns.lineplot(x='attributes', y='avgFScores', data=scoresDF)\n",
    "plt.xlabel('Number of Attributes')\n",
    "plt.ylabel('Average F-score')\n",
    "plt.title('Average F-score of Predictions vs Number of Attributes Used')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35a94c",
   "metadata": {},
   "source": [
    "#### Testing highest fscores of each number of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highestFScores = {\n",
    "#     'fScores': [],\n",
    "#     'winningAttributes': [],\n",
    "#     'attributes': []\n",
    "# }\n",
    "# for i in range(1, len(df.drop('class', axis=1).columns)+1):\n",
    "#     highestFScores['attributes'].append(i)\n",
    "#     highestF = 0\n",
    "#     bestAttributes = []\n",
    "#     for j in range(50):\n",
    "#         scores, attributes = testDataset(dataframe=df, testCol='class', attributes=i, verbose=False)\n",
    "#         if scores[2] > highestF:\n",
    "#             highestF = scores[2]\n",
    "#             bestAttributes = attributes\n",
    "#     highestFScores['fScores'].append(highestF)\n",
    "#     highestFScores['winningAttributes'].append(bestAttributes)\n",
    "\n",
    "# display(highestFScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95817aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='attributes', y='highestFScores', data=scoresDF)\n",
    "plt.xlabel('Number of Attributes')\n",
    "plt.ylabel('Highest F-score')\n",
    "plt.title('Highest F-score of Predictions vs Number of Attributes Used')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86e093",
   "metadata": {},
   "source": [
    "#### Plotting Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ab5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scoresDF['attributes']\n",
    "y1 = scoresDF['highestFScores']\n",
    "y2 = scoresDF['avgFScores']\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(x, y1, color='tab:blue')\n",
    "ax1.set_ylabel('Highest F-score', color='tab:blue')\n",
    "\n",
    "ax1.set_ylim(min(min(y1), min(y2)), 1)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, y2, color='tab:red')\n",
    "ax2.set_ylabel('Average F-score', color='tab:red')\n",
    "\n",
    "ax2.set_ylim(min(min(y1), min(y2)), 1)\n",
    "\n",
    "ax1.set_xlabel('Number of Attributes')\n",
    "ax1.set_title('Highest F-score and Average F-score of Predictions vs Number of Attributes Used')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ec9c4",
   "metadata": {},
   "source": [
    "### Narrowing Down the Best Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset(df, 'class', ['stalk_surface_ar',\n",
    "   'gill_spacing',\n",
    "   'bruises',\n",
    "   'cap_color',\n",
    "   'gill_attachment',\n",
    "   'gill_size'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset(df, 'class', ['cap_color',\n",
    "  'bruises',\n",
    "  'stalk_surface_ar',\n",
    "  'gill_attachment',\n",
    "  'gill_size',\n",
    "  'gill_spacing',\n",
    "  'stalk_surface_br'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset(df, 'class', ['gill_size',\n",
    "  'stalk_shape',\n",
    "  'gill_attachment',\n",
    "  'veil_color',\n",
    "  'ring_number',\n",
    "  'gill_spacing',\n",
    "  'cap_color',\n",
    "  'bruises'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset(df, 'class', ['gill_size',\n",
    "  'veil_type',\n",
    "  'gill_spacing',\n",
    "  'gill_attachment',\n",
    "  'bruises',\n",
    "  'stalk_color_br',\n",
    "  'stalk_color_ar',\n",
    "  'veil_color',\n",
    "  'cap_color'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset(df, 'class', ['gill_attachment',\n",
    "  'cap_shape',\n",
    "  'stalk_surface_ar',\n",
    "  'stalk_color_br',\n",
    "  'odor',\n",
    "  'bruises',\n",
    "  'stalk_shape',\n",
    "  'stalk_color_ar',\n",
    "  'gill_size',\n",
    "  'ring_number',\n",
    "  'gill_spacing'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "topContenders = [\n",
    "    ['stalk_surface_ar',\n",
    "   'gill_spacing',\n",
    "   'bruises',\n",
    "   'cap_color',\n",
    "   'gill_attachment',\n",
    "   'gill_size'],\n",
    "   ['cap_color',\n",
    "  'bruises',\n",
    "  'stalk_surface_ar',\n",
    "  'gill_attachment',\n",
    "  'gill_size',\n",
    "  'gill_spacing',\n",
    "  'stalk_surface_br'],\n",
    "  ['gill_size',\n",
    "  'stalk_shape',\n",
    "  'gill_attachment',\n",
    "  'veil_color',\n",
    "  'ring_number',\n",
    "  'gill_spacing',\n",
    "  'cap_color',\n",
    "  'bruises'],\n",
    "  ['gill_size',\n",
    "  'veil_type',\n",
    "  'gill_spacing',\n",
    "  'gill_attachment',\n",
    "  'bruises',\n",
    "  'stalk_color_br',\n",
    "  'stalk_color_ar',\n",
    "  'veil_color',\n",
    "  'cap_color'],\n",
    "  ['gill_attachment',\n",
    "  'cap_shape',\n",
    "  'stalk_surface_ar',\n",
    "  'stalk_color_br',\n",
    "  'odor',\n",
    "  'bruises',\n",
    "  'stalk_shape',\n",
    "  'stalk_color_ar',\n",
    "  'gill_size',\n",
    "  'ring_number',\n",
    "  'gill_spacing']\n",
    "]\n",
    "top = 0\n",
    "topAttributes = []\n",
    "for combo in topContenders:\n",
    "    avgFScore = 0\n",
    "    for i in range(50):\n",
    "        s, a = testDataset(df, 'class', combo, verbose=False)\n",
    "        avgFScore += s[2]\n",
    "    avgFScore = avgFScore / 50\n",
    "    if avgFScore > top:\n",
    "        top = avgFScore\n",
    "        topAttributes = a\n",
    "\n",
    "print(f'The best attributes to use for predicting the edibility of mushrooms are {topAttributes}, which yield an average F-score of about {top}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf003814",
   "metadata": {},
   "source": [
    "### Performance of the Best Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966dbc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[topAttributes]\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)#, random_state=42)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_pred, labels=[0, 1])\n",
    "print(p, r, f, s)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f31fb",
   "metadata": {},
   "source": [
    "### Finding Attributes That Are Good Predictors by Themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91249e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "commonFeatures = {}\n",
    "for feature in features:\n",
    "    commonFeatures[feature] = 0\n",
    "\n",
    "for i in range(1, len(df.drop('class', axis=1).columns)+1):\n",
    "    for j in range(50):\n",
    "        scores, attributes = testDataset(dataframe=df, testCol='class', attributes=i, verbose=False)\n",
    "        if scores[2] > 0.85:\n",
    "            for a in attributes:\n",
    "                commonFeatures[a] += 1\n",
    "\n",
    "display(commonFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46883de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'attribute': [],\n",
    "    'count': []\n",
    "}\n",
    "for key, value in commonFeatures.items():\n",
    "    data['attribute'].append(key)\n",
    "    data['count'].append(value)\n",
    "\n",
    "attributeCountsDF = pd.DataFrame(data)\n",
    "attributeCountsDF = attributeCountsDF[attributeCountsDF.attribute != 'class']\n",
    "attributeCountsDF = attributeCountsDF.sort_values(by='count')\n",
    "display(attributeCountsDF)\n",
    "\n",
    "sns.barplot(x='attribute', y='count', data=attributeCountsDF)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Attribute')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count per Attribute of Appearances in Attribute Combinations Yielding an F-score > 0.85')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6d743",
   "metadata": {},
   "source": [
    "#### A Look at a Few of Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "bruisesDF = df.groupby(['bruises', 'class'])['habitat'].count().reset_index()\n",
    "bruisesDF['bruises'] = bruisesDF['bruises'].map(encodings['bruises'])\n",
    "bruisesDF['class'] = bruisesDF['class'].map(encodings['class'])\n",
    "\n",
    "sns.barplot(x='bruises', y='habitat', hue='class', data=bruisesDF)\n",
    "plt.xlabel('Has Bruises')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Mushrooms vs Presence of Bruises')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621acd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bruisesDF = df.groupby(['bruises', 'class'])['habitat'].count().reset_index()\n",
    "bruisesDF['bruises'] = bruisesDF['bruises'].map(encodings['bruises'])\n",
    "bruisesDF['class'] = bruisesDF['class'].map(encodings['class'])\n",
    "\n",
    "sns.barplot(x='class', y='habitat', hue='bruises', data=bruisesDF)\n",
    "plt.xlabel('Edibility')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Mushrooms vs Edibility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e916a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gillSpacingDF = df.groupby(['gill_spacing', 'class'])['habitat'].count().reset_index()\n",
    "gillSpacingDF['gill_spacing'] = gillSpacingDF['gill_spacing'].map(encodings['gill_spacing'])\n",
    "gillSpacingDF['class'] = gillSpacingDF['class'].map(encodings['class'])\n",
    "\n",
    "sns.barplot(x='gill_spacing', y='habitat', hue='class', data=gillSpacingDF)\n",
    "plt.xlabel('Gill Spacing')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Mushrooms vs Gill Spacing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf0f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "gillSpacingDF = df.groupby(['gill_spacing', 'class'])['habitat'].count().reset_index()\n",
    "gillSpacingDF['gill_spacing'] = gillSpacingDF['gill_spacing'].map(encodings['gill_spacing'])\n",
    "gillSpacingDF['class'] = gillSpacingDF['class'].map(encodings['class'])\n",
    "\n",
    "sns.barplot(x='class', y='habitat', hue='gill_spacing', data=gillSpacingDF)\n",
    "plt.xlabel('Edibility')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Mushrooms vs Edibility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "populationDF = df.groupby(['population', 'class'])['habitat'].count().reset_index()\n",
    "populationDF['population'] = populationDF['population'].map(encodings['population'])\n",
    "populationDF['class'] = populationDF['class'].map(encodings['class'])\n",
    "\n",
    "sns.barplot(x='population', y='habitat', hue='class', data=populationDF)\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Mushrooms vs Population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "populationDF = df.groupby(['population', 'class'])['habitat'].count().reset_index()\n",
    "populationDF['population'] = populationDF['population'].map(encodings['population'])\n",
    "populationDF['class'] = populationDF['class'].map(encodings['class'])\n",
    "\n",
    "sns.barplot(x='class', y='habitat', hue='population', data=populationDF)\n",
    "plt.xlabel('Edibility')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Mushrooms vs Edibility')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
